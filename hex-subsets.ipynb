{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1bc1add-08d7-4d06-9bc6-512e6460442e",
   "metadata": {},
   "source": [
    "# Subsetting data by Hex ID\n",
    "\n",
    "This notebook explores the ability to do fast spatial subsets as H3 Hex operations.  We may also benchmark these against spatial filters. Note this uses some small helper methods from our [boettiger-lab/cng-python](https://github.com/boettiger-lab/cng-python) repo; be sure to have the latest version. \n",
    "\n",
    "For the moment this focuses on vector data, though it is of course possible to consider a similar spatial grid approach to rasters as well.  Almost everything here are just simple duckdb operations using the `h3` extension, see [h3-duckdb](https://github.com/isaacbrodsky/h3-duckdb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5111d7b-36ae-4ba7-be86-5f2b5d669feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/boettiger-lab/cng-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da79b893-9929-45c3-8b9a-46b061764e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibis\n",
    "from ibis import _\n",
    "from cng.utils import *\n",
    "from cng.maps import *\n",
    "from cng.h3 import *\n",
    "import os\n",
    "import re\n",
    "import leafmap.maplibregl as leafmap\n",
    "\n",
    "con = ibis.duckdb.connect(extensions = [\"spatial\", \"h3\"])\n",
    "endpoint = os.getenv(\"AWS_S3_ENDPOINT\", \"minio.carlboettiger.info\")\n",
    "\n",
    "set_secrets(con)\n",
    "duckdb_install_h3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efbec41-3856-4ef3-8a03-b509adc7998b",
   "metadata": {},
   "source": [
    "In the [datasets](https://github.com/boettiger-lab/datasets) repo there is code for that generates cloud-native versions of most of our vector datasets.   For many of these, I've computed h3-indexed versions of the data as well, usually at one or more resolutions.  For point data like GBIF, it is natural to do all the resolutions in a single table.  For polygons, we tile the polygons with h3 hexes of varying resolutions, so something like census tracts at zoom 10 needs quite a lot more rows than it does at zoom 8, and it makes sense for maximum performance to have both available as separate files.  \n",
    "\n",
    "When necessary, we can use `h3_cell_to_parent` or `h3_cell_to_children` method to compute a lower or higher resolution hex from one that we already have, but obviously it is faster if we already have precomputed at the correct resolution. \n",
    "\n",
    "**Note** the hex columns are not entirely standardized yet.  for instance `pad` at zoom 10 is stored in nested array format, rather than as one row per hexid.  Note we can unnest if hex cells are in 'array' format, e.g. `mutate(h8 = h3_cell_to_parent(_.h10.unnest(), 8))`, if necessary.  Also ensure that hexid columns share the same name (I usually use the convention that a hex id column at zoom 8 is called `h8`), and that it is a lower-case string (hexes can be stored as strings in upper or lowercase, or as big integers.  Ultimately it may be faster to use the integer format, though some tools like maplibre will need this cast to strings to render).  \n",
    "\n",
    "\n",
    "For this example we will subset the Protected Areas Data using the 2022 Census Tracts data, both at zoom-8 resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3975e4c0-7b01-4c51-aa96-22a4b2c62f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom = 8\n",
    "pad =  con.read_parquet(f\"s3://public-biodiversity/pad-us-4/pad-h3-z{zoom}.parquet\")\n",
    "tracts = con.read_parquet(f\"s3://public-social-vulnerability/2022-tracts-h3-z{zoom}.parquet\").mutate(h8 = _.h8.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb01b81-6897-4dec-92aa-6b2e61994412",
   "metadata": {},
   "source": [
    "\n",
    "It is very fast to filter the PAD data to any arbitrary selection of State(s), Counties, or Tracts from the census data this way.  (While for a single polygon this may not always be faster than a spatially explicit filter, this can be very useful for large-scale joins).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85899bd0-944d-44c0-a350-1552af8a1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we go: do subset:\n",
    "\n",
    "aoi = tracts.filter(_.STATE.isin([\"Arizona\", \"New Mexico\"])).join(pad, \"h8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3164d539-218f-4d87-beaa-1d259552716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join hex version to the original pad_parquet that has all the columns \n",
    "pad_full =  con.read_parquet(f\"s3://public-biodiversity/pad-us-4/pad-us-4.parquet\")\n",
    "\n",
    "\n",
    "aoi_pad = aoi.join(pad_full, \"row_n\").filter(_.GAP_Sts.isin([\"1\", \"2\"]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef54582a-ac1a-45a7-b11d-69102871a2be",
   "metadata": {},
   "source": [
    "## Subsetting and Visualizing \n",
    "\n",
    "Note that the hexid versions of the datasets do not (always) include all the columns of the original dataset, as they are intended for filtering.  It is usually pretty quick to join them against the original tables to get all the other columns. \n",
    "\n",
    "\n",
    "For drawing on a map, there are a few possible strategies that should scale well: \n",
    "\n",
    "\n",
    "- We could now filter the PMTiles for those matching the ID,\n",
    "- or we can plot the hexes directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c0f7cb-9147-4520-bcd5-9c2acc4d1ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a00b395-cf6b-497b-8f2a-bcdc87e90f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae369e5a3bd401c9bcdeaa1bf69411a",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Map(height='600px', map_options={'bearing': 0, 'center': (0, 20), 'pitch': 0, 'style': {'version': 8, 'sources…"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter PMTiles\n",
    "\n",
    "row_ids = aoi_pad.select('row_n').distinct().execute().iloc[:, 0].tolist()\n",
    "\n",
    "def get_filter(column, values):\n",
    "    return [\"in\", [\"get\", column], [\"literal\", values]]\n",
    "    #return [\"all\", [\"match\", [\"get\", column], values, True, False]]\n",
    "\n",
    "\n",
    "\n",
    "pmtiles = f\"https://{endpoint}/public-biodiversity/pad-us-4/pad-us-4.pmtiles\"\n",
    "\n",
    "style = {\n",
    "        \"version\": 8,\n",
    "        \"sources\": {\"pmtiles\": {\"type\": \"vector\", \"url\": f\"pmtiles://{pmtiles}\"}},\n",
    "        \"layers\": [\n",
    "            {\n",
    "                \"id\": \"pad\",\n",
    "                \"source\": \"pmtiles\",\n",
    "                \"source-layer\": \"padus4\",\n",
    "                \"type\": \"fill\",\n",
    "                \"filter\": get_filter(\"row_n\", row_ids),\n",
    "                \"paint\": {\"fill-color\": \"blue\", \"fill-opacity\": 0.7},\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "m = leafmap.Map(style=terrain_style())\n",
    "m.add_pmtiles(url=pmtiles, style=style, fit_bounds=True)\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30306f34-6f85-445c-914e-551f41339a8f",
   "metadata": {},
   "source": [
    "## Plotting as Hexes\n",
    "\n",
    "Or we can plot the hexes directly instead of PMTiles polygons.  To do this, we can write them directly to a bucket as JSON. While not as performant in rendering as PMTiles, the JSON hexes are relatively fast to write:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81865906-3bfd-4388-b650-7ca3cd25acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"s3://public-data/cache/map/ex.json\"\n",
    "to_json(aoi_pad.select(\"GAP_Sts\", \"h8\").rename(h3id = \"h8\"), path)\n",
    "\n",
    "# turn s3 path to URL\n",
    "url = re.sub(\"s3://\", f\"https://{endpoint}/\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0047f5ed-70d3-4e55-981c-0e9e60a31690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baae3e62f618422688d57cd4bf3ac833",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Map(height='600px', map_options={'bearing': 0, 'center': (0, 20), 'pitch': 0, 'style': {'version': 8, 'sources…"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cng.maps import *\n",
    "\n",
    "url = 'https://minio.carlboettiger.info/public-data/cache/map/ex.json'\n",
    "\n",
    "layer = HexagonLayer(url, 1)\n",
    "\n",
    "m = leafmap.Map(style=terrain_style())\n",
    "m.add_deck_layers([layer])\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
